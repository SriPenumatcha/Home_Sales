# Home_Sales


## Overview

This project involves analyzing home sales data using SparkSQL. The goal is to determine key metrics, cache and uncache a temporary table, and compare query performance. 
The analysis is performed on data read from a CSV file, and parquet file formats are used for partitioning and performance evaluation.

## Technologies Used

- PySpark

- SparkSQL

- Google Colab




## Folder Structure 

The Home_Sales challenge consists of the following folders and files:

* **Home_Sales folder**:

   * Home_Sales.jpynb   -  The Jupyter Notebook file containing the code & analysis. 
   
   * README.md - Provides the Overview of the analysis and project folder Structure



## How to Use

1. Clone the GitHub repository to your local machine using the following command:

    git clone https://github.com/SriPenumatcha/Home_Sales.git

2. Open the `Home_Sales.jpynb' file using Google Colab.

3. Run each cell in the notebook to perform the analysis and view the results.

